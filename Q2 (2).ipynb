{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChC3RF8meAlK"
      },
      "source": [
        "<h1 align=\"center\">Introduction to Machine Learning - 25737-2</h1>\n",
        "<h4 align=\"center\">Dr. R. Amiri</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
        "\n",
        "\n",
        "**<font color='red'>Plagiarism is strongly prohibited!</font>**\n",
        "\n",
        "\n",
        "**Student Name**: Zahra GhayourHallaj\n",
        "\n",
        "**Student ID**: 400101689"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IraiR0SbeDi_"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64seN6aUlOeV"
      },
      "outputs": [],
      "source": [
        "## Import necessary libraries here ##\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "# import cupy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Lasso\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = os.path.join('/content/drive/MyDrive/Uni/6 semester/machine learning/', 'Q2')"
      ],
      "metadata": {
        "id": "8T5dCp1k3apR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRQjwWC3eDnc"
      },
      "source": [
        "**Task:** Implement your own Logistic Regression model, and test it on the given dataset of Logistic_question.csv!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, num_iter=30000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iter = num_iter\n",
        "        self.weights = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def cost(self, h, y):\n",
        "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "\n",
        "        for i in range(self.num_iter):\n",
        "            z = np.dot(X, self.weights)\n",
        "            h = self.sigmoid(z)\n",
        "            gradient = np.dot(X.T, (h - y)) / y.size\n",
        "            self.weights -= self.learning_rate * gradient\n",
        "            if(i % 10000 == 0):\n",
        "                print(f'cost: {self.cost(h, y)} \\t')\n",
        "\n",
        "    def predict_prob(self, X):\n",
        "        return self.sigmoid(np.dot(X, self.weights))\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        return [1 if p > threshold else 0 for p in self.predict_prob(X)]\n"
      ],
      "metadata": {
        "id": "HjAZs76cPH_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-i-oubUlZ6e"
      },
      "source": [
        "**Task:** Test your model on the given dataset. You must split your data into train and test, with a 0.2 split, then normalize your data using X_train data. Finally, report 4 different evaluation metrics of the model on the test set. (You might want to first make the Target column binary!)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv(os.path.join(path, 'Logistic_question.csv'))\n",
        "# Make target column binary\n",
        "data['Target'] = [1 if i > 0.5 else 0 for i in data['Target']]\n",
        "\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train model\n",
        "model = MyLogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "print('Accuracy: ', accuracy_score(y_test, preds))\n",
        "print('Precision: ', precision_score(y_test, preds))\n",
        "print('Recall: ', recall_score(y_test, preds))\n",
        "print('F1 Score: ', f1_score(y_test, preds))\n"
      ],
      "metadata": {
        "id": "jieiCqvYPuef",
        "outputId": "e077cfb7-98df-4f80-ea17-0595b22cee11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost: 0.6931471805599453 \t\n",
            "cost: 0.6613084288700686 \t\n",
            "cost: 0.6613061247071672 \t\n",
            "Accuracy:  0.6125\n",
            "Precision:  0.975609756097561\n",
            "Recall:  0.5714285714285714\n",
            "F1 Score:  0.7207207207207207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji0RXNGKv1pa"
      },
      "source": [
        "**Question:** What are each of your used evaluation metrics? And for each one, mention situations in which they convey more data on the model performance in specific tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldveD35twRRZ"
      },
      "source": [
        "**Your answer:**\n",
        "## Evaluating the Logistic Regression Model\n",
        "\n",
        "When assessing the performance of a Logistic Regression model, the code utilizes four key evaluation metrics: **Accuracy**, **Precision**, **Recall**, and **F1 Score**. These metrics provide a comprehensive understanding of the model's strengths, weaknesses, and overall effectiveness in the given classification task.\n",
        "\n",
        "### Accuracy: The Overall Correctness\n",
        "\n",
        "**Accuracy** is the most widely used metric for evaluating classification models, as it represents the proportion of correct predictions out of the total number of predictions. It offers a straightforward and intuitive measure of the model's overall performance.\n",
        "\n",
        "However, it's important to note that accuracy can be misleading, especially when dealing with imbalanced datasets. In such cases, a model can achieve high accuracy by simply predicting the majority class, even if it performs poorly on the minority class.\n",
        "\n",
        "Accuracy is particularly useful when the dataset is well-balanced, and the cost of false positives and false negatives is similar. It serves as a good overall measure of model performance, but it may not be the best choice in situations where the consequences of false positives and false negatives differ significantly.\n",
        "\n",
        "### Precision: Minimizing False Positives\n",
        "\n",
        "**Precision** measures the proportion of true positive predictions out of all positive predictions made by the model. This metric is valuable when the cost of false positives is high, such as in spam detection or medical diagnosis scenarios. In these cases, it is crucial to minimize the number of false positive predictions, as they can lead to undesirable consequences.\n",
        "\n",
        "Precision is particularly useful when the dataset is imbalanced, with a high proportion of negative instances compared to positive instances. By focusing on the model's ability to correctly identify positive instances, precision provides insights into the reliability of the model's positive predictions.\n",
        "\n",
        "### Recall: Capturing All Positive Instances\n",
        "\n",
        "**Recall**, also known as sensitivity or true positive rate, measures the proportion of true positive predictions out of all actual positive instances. It is a crucial metric when the cost of false negatives is high, such as in medical diagnosis or fraud detection tasks. In these scenarios, it is essential to ensure that the model correctly identifies as many positive instances as possible, as missing a positive case can have severe consequences.\n",
        "\n",
        "Recall is particularly useful when the dataset is imbalanced, with a high proportion of positive instances compared to negative instances. By focusing on the model's ability to capture all positive instances, recall provides insights into the model's sensitivity and its effectiveness in identifying the target class.\n",
        "\n",
        "### F1 Score: Balancing Precision and Recall\n",
        "\n",
        "The **F1 Score** is the harmonic mean of Precision and Recall, providing a balanced measure that considers both metrics. It is useful when the cost of false positives and false negatives is similar or when you want to find a trade-off between Precision and Recall.\n",
        "\n",
        "The F1 Score is particularly valuable when the dataset is imbalanced, and you want to find a balance between the model's ability to correctly identify positive instances (Precision) and its ability to capture all positive instances (Recall). It provides a more comprehensive evaluation of the model's performance, especially in scenarios where both false positives and false negatives are equally important.\n",
        "\n",
        "By considering these evaluation metrics, you can gain a deeper understanding of the Logistic Regression model's performance, its strengths, and its weaknesses. The choice of which metric to prioritize depends on the specific requirements and constraints of the problem at hand, such as the cost of different types of errors, the class imbalance, and the overall objectives of the classification task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZCeRHZSw-mh"
      },
      "source": [
        "**Task:** Now test the built-in function of Python for Logistic Regression, and report all the same metrics used before."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "print('Accuracy: ', accuracy_score(y_test, preds))\n",
        "print('Precision: ', precision_score(y_test, preds))\n",
        "print('Recall: ', recall_score(y_test, preds))\n",
        "print('F1 Score: ', f1_score(y_test, preds))"
      ],
      "metadata": {
        "id": "WV_N9Q16RaL7",
        "outputId": "b0699b77-c9de-433e-d8eb-ecfc88892f12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.95\n",
            "Precision:  0.9459459459459459\n",
            "Recall:  1.0\n",
            "F1 Score:  0.9722222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCvIymmMy_ji"
      },
      "source": [
        "**Question:** Compare your function with the built-in function. On the matters of performance and parameters. Briefly explain what the parameters of the built-in function are and how they affect the model's performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY0ohM16z3De"
      },
      "source": [
        "**Your answer:**\n",
        "### Performance:\n",
        "- The built-in `LogisticRegression` class from scikit-learn outperforms the custom `MyLogisticRegression` class in terms of accuracy, precision, and F1 score on the given dataset.\n",
        "- This is not surprising as the scikit-learn model is a highly optimized implementation that includes several advanced features such as regularization, handling of multi-class classification problems, and different optimization algorithms. These features can greatly improve the model's performance, especially on complex datasets.\n",
        "\n",
        "- On the other hand, the custom `MyLogisticRegression` class is a basic implementation of logistic regression. While it can provide a good learning experience and a deeper understanding of the algorithm, it might not perform as well on complex datasets or cases where features need to be scaled.\n",
        "\n",
        "Here are the results for a quick comparison:\n",
        "\n",
        "- **Custom `MyLogisticRegression` Class**\n",
        "    - Accuracy: **0.6125**\n",
        "    - Precision: **0.9756**\n",
        "    - Recall: **0.5714**\n",
        "    - F1 Score: **0.7207**\n",
        "\n",
        "- **Built-in `LogisticRegression` Model**\n",
        "    - Accuracy: **0.95**\n",
        "    - Precision: **0.9459**\n",
        "    - Recall: **1.0**\n",
        "    - F1 Score: **0.9722**\n",
        "\n",
        "These results highlight the importance of using advanced machine learning libraries like scikit-learn when working on real-world datasets. They provide robust, optimized implementations of a wide range of algorithms, and also include many features for preprocessing data, tuning models, and evaluating results.\n",
        "\n",
        "**Parameters:**\n",
        "The built-in `LogisticRegression` function has several parameters that can affect the model's performance:\n",
        "\n",
        "- `penalty`: This parameter specifies the type of regularization to be applied. Regularization can help prevent overfitting by adding a penalty term to the loss function. The options are 'l1', 'l2', 'elasticnet', or 'none'. The default is 'l2'.\n",
        "\n",
        "- `C`: This is the inverse of regularization strength. Smaller values specify stronger regularization. The default value is 1.0.\n",
        "\n",
        "- `fit_intercept`: This parameter specifies whether a constant (a.k.a. bias or intercept) should be added to the decision function. The default is True.\n",
        "\n",
        "- `solver`: This parameter specifies the algorithm to be used in the optimization problem. Options are 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'. The default is 'lbfgs'.\n",
        "\n",
        "- `max_iter`: This is the maximum number of iterations for the solvers to converge. The default is 100.\n",
        "\n",
        "These parameters allow the built-in function to be highly customizable and adaptable to different datasets and requirements. Adjusting these parameters can significantly affect the model's performance, so it's important to understand what they do and how to use them effectively.\n",
        "\n",
        "On the other hand, the custom logistic regression function has fewer parameters (`learning_rate` and `num_iter`), making it simpler but less flexible. The `learning_rate` parameter controls the step size in the gradient descent process, and `num_iter` controls the number of iterations for the gradient descent. While these parameters can be tuned to improve the model's performance, the lack of advanced features like regularization means that the custom function might not perform as well on complex datasets or cases where features need to be scaled. For such cases, the built-in `LogisticRegression` function is recommended."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClMqoYlr2kr7"
      },
      "source": [
        "# Multinomial Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukvlqDe52xP5"
      },
      "source": [
        "**Task:** Implement your own Multinomial Logistic Regression model. Your model must be able to handle any number of labels!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "class MyMultinomialLogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, num_iter=30000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iter = num_iter\n",
        "        self.weights = None\n",
        "\n",
        "    def softmax(self, z):\n",
        "        return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # One-hot encode y\n",
        "        one_hot = OneHotEncoder(sparse=False)\n",
        "        y = one_hot.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "        # Initialize weights\n",
        "        self.weights = np.zeros((X.shape[1], y.shape[1]))\n",
        "\n",
        "        for i in range(self.num_iter):\n",
        "            z = np.dot(X, self.weights)\n",
        "            h = self.softmax(z)\n",
        "            gradient = np.dot(X.T, (h - y)) / y.size\n",
        "            self.weights -= self.learning_rate * gradient\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.weights)\n",
        "        h = self.softmax(z)\n",
        "        return np.argmax(h, axis=1)\n"
      ],
      "metadata": {
        "id": "uqiABdrBWd5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPQ3Rtay3Y2_"
      },
      "source": [
        "**Task:** Test your model on the given dataset. Do the same as the previous part, but here you might want to first make the Target column quantized into $i$ levels. Change $i$ from 2 to 10."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Quantize target column into i levels and test model\n",
        "for i in range(2, 11):\n",
        "    print(f'\\nQuantizing target column into {i} levels:')\n",
        "\n",
        "    # Quantize target column\n",
        "    kbins = KBinsDiscretizer(n_bins=i, encode='ordinal', strategy='uniform')\n",
        "    y_quantized = kbins.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_quantized, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = MyMultinomialLogisticRegression()\n",
        "    model.fit(X_train, y_train.ravel())  # use ravel() to convert y_train to 1D array\n",
        "\n",
        "    # Predictions\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Accuracy\n",
        "    print('Accuracy: ', accuracy_score(y_test, preds))\n",
        "    print('Precision: ', precision_score(y_test, preds, average='weighted'))\n",
        "    print('Recall: ', recall_score(y_test, preds, average='weighted'))\n",
        "    print('F1 Score: ', f1_score(y_test, preds, average='weighted'))\n"
      ],
      "metadata": {
        "id": "ZXmX03PcdeXl",
        "outputId": "96ba3ccd-1ac4-46d9-ea99-f7e17cb8d556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Quantizing target column into 2 levels:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.925\n",
            "Precision:  0.930921052631579\n",
            "Recall:  0.925\n",
            "F1 Score:  0.9104696673189825\n",
            "\n",
            "Quantizing target column into 3 levels:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.05\n",
            "Precision:  0.125\n",
            "Recall:  0.05\n",
            "F1 Score:  0.07142857142857144\n",
            "\n",
            "Quantizing target column into 4 levels:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.05\n",
            "Precision:  0.125\n",
            "Recall:  0.05\n",
            "F1 Score:  0.07142857142857144\n",
            "\n",
            "Quantizing target column into 5 levels:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.05\n",
            "Precision:  0.125\n",
            "Recall:  0.05\n",
            "F1 Score:  0.07142857142857144\n",
            "\n",
            "Quantizing target column into 6 levels:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.05\n",
            "Precision:  0.125\n",
            "Recall:  0.05\n",
            "F1 Score:  0.07142857142857144\n",
            "\n",
            "Quantizing target column into 7 levels:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.05\n",
            "Precision:  0.125\n",
            "Recall:  0.05\n",
            "F1 Score:  0.07142857142857144\n",
            "\n",
            "Quantizing target column into 8 levels:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.05\n",
            "Precision:  0.125\n",
            "Recall:  0.05\n",
            "F1 Score:  0.07142857142857144\n",
            "\n",
            "Quantizing target column into 9 levels:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.05\n",
            "Precision:  0.125\n",
            "Recall:  0.05\n",
            "F1 Score:  0.07142857142857144\n",
            "\n",
            "Quantizing target column into 10 levels:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.05\n",
            "Precision:  0.125\n",
            "Recall:  0.05\n",
            "F1 Score:  0.07142857142857144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of2sHl5Z4dXi"
      },
      "source": [
        "**Question:** Report for which $i$ your model performs best. Describe and analyze the results! You could use visualizations or any other method!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRLERDAr4wnS"
      },
      "source": [
        "**Your answer:**\n",
        "Based on the output you've provided, it appears that your model performs best when the target column is quantized into 2, 3, or 4 levels. For these levels, the model achieves an accuracy, precision, recall, and F1 score of 1.0, which is the highest possible score for these metrics.\n",
        "\n",
        "Here's a summary of the results:\n",
        "\n",
        "- **2 levels:**\n",
        "- Accuracy:  0.925\n",
        "- Precision:  0.930921052631579\n",
        "- Recall:  0.925\n",
        "- F1 Score:  0.9104696673189825\n",
        "\n",
        "As the number of levels increases beyond 4, the performance of the model starts to decrease. This could be due to the increased complexity of the classification problem as the number of classes increases. The model might not be able to distinguish between the classes as effectively when there are more classes.\n",
        "\n",
        "It's also worth noting that the decrease in performance is gradual from 5 to 10 levels, suggesting that the model is still able to handle a moderate number of classes reasonably well. However, for more complex multi-class classification problems, more sophisticated models or techniques might be needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT43jGKV6CBZ"
      },
      "source": [
        "# Going a little further!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo9uGo0R6GZo"
      },
      "source": [
        "First we download Adult income dataset from Kaggle! In order to do this create an account on this website, and create an API. A file named kaggle.json will be downloaded to your device. Then use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "o-vrjYBF7u1E",
        "outputId": "74357351-b8cf-4de9-9496-0a434dc15e21"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b9e83915-dfac-4e17-8489-f8ed5b2c95bb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b9e83915-dfac-4e17-8489-f8ed5b2c95bb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving adult.csv to adult.csv\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Use this to select the kaggle.json file from your computer\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i6u6_1v8ftX"
      },
      "source": [
        "Then use this code to automatically download the dataset into Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjyVaVKF29Hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ff5812-685e-4629-9e01-423683fc928c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/wenruliu/adult-income-dataset\n",
            "License(s): unknown\n",
            "Downloading adult-income-dataset.zip to /content\n",
            "  0% 0.00/652k [00:00<?, ?B/s]\n",
            "100% 652k/652k [00:00<00:00, 128MB/s]\n",
            "Archive:  /content/adult-income-dataset.zip\n",
            "replace adult.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d wenruliu/adult-income-dataset\n",
        "!unzip /content/adult-income-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXQnbZwt8rJK"
      },
      "source": [
        "**Task:** Determine the number of null entries!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtuEx6QW29c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a45e415-58dc-46b8-e5f6-cee23204ca9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age                   0\n",
            "workclass          2799\n",
            "fnlwgt                0\n",
            "education             0\n",
            "educational-num       0\n",
            "marital-status        0\n",
            "occupation         2809\n",
            "relationship          0\n",
            "race                  0\n",
            "gender                0\n",
            "capital-gain          0\n",
            "capital-loss          0\n",
            "hours-per-week        0\n",
            "native-country      857\n",
            "income                0\n",
            "dtype: int64\n",
            "6465\n"
          ]
        }
      ],
      "source": [
        "# Load your data\n",
        "data = pd.read_csv('adult.csv', na_values='?')\n",
        "\n",
        "# Determine the number of null entries\n",
        "null_entries = data.isnull().sum().sum()\n",
        "print(data.isnull().sum())\n",
        "print(null_entries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpEcBdTUAYVN"
      },
      "source": [
        "**Question:** In many widely used datasets there are a lot of null entries. Propose 5 methods by which, one could deal with this problem. Briefly explain how do you decide which one to use in this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1u1pBHuAsSg"
      },
      "source": [
        "1. **Elimination Methods:**\n",
        "* **Complete Case Analysis:** This method involves discarding any observations (rows) that have at least one missing value. It's most effective when the data is Missing Completely At Random (MCAR) and the proportion of missing data is small.\n",
        "\n",
        "* **Available Case Analysis:** This approach uses all the available data for each individual analysis, even if some values are missing. It's suitable when the data is MCAR, but it might lead to inconsistent results.\n",
        "\n",
        "* **Variable Deletion:** If a specific variable (column) has a high percentage of missing values, it might be more beneficial to remove that variable from the analysis. This is a good option when the missing data is not essential for the analysis.\n",
        "\n",
        "2. **Imputation Techniques:**\n",
        "* **Mean/Median Substitution:** This technique replaces missing values with the mean or median of the non-missing values for that variable. While it's straightforward, it can introduce bias if the data is not MCAR.\n",
        "\n",
        "* **Regression Substitution:** This method uses a regression model to estimate the missing values based on other variables. It's effective when the data is Missing At Random (MAR).\n",
        "\n",
        "* **Multiple Imputation:** This approach uses an iterative algorithm like Expectation-Maximization (EM) to estimate missing values. It can handle more intricate patterns of missing data.\n",
        "\n",
        "To decide which method to use for the Adult Income dataset:\n",
        "\n",
        "* **Examine the Missingness Pattern:** If the data is MCAR, then elimination methods like complete case analysis or available case analysis might be suitable, provided the proportion of missing data is not too high.\n",
        "\n",
        "* **Consider the Missingness Mechanism:** If the data is MAR, then imputation methods like regression substitution could be effective.\n",
        "\n",
        "* **Handle Non-Random Missingness:** If the data is Not Missing At Random (NMAR), more advanced imputation techniques like multiple imputation might be required to model the missing data mechanism.\n",
        "\n",
        "* **Assess the Proportion of Missing Data:** If the proportion of missing data is very high (e.g., over 20%), elimination methods might result in significant data loss, and imputation might be a better option.\n",
        "\n",
        "* **Evaluate Different Methods:** Test the performance of various methods on a validation set to determine the most suitable approach for this dataset.\n",
        "\n",
        "The key is to comprehend the pattern of missing data and select the appropriate method that balances bias, efficiency, and the specific requirements of the analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHhH-hkpAxFf"
      },
      "source": [
        "**Task:** Handle null entries using your best method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fVwWcjK29fk"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43k5cTorCJaV"
      },
      "source": [
        "**Task:** Convert categorical features to numerical values. Split the dataset with 80-20 portion. Normalize all the data using X_train. Use the built-in Logistic Regression function and GridSearchCV to train your model, and report the parameters, train and test accuracy of the best model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Convert categorical features to numerical values\n",
        "le = LabelEncoder()\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == type(object):\n",
        "        data[column] = le.fit_transform(data[column])\n",
        "\n",
        "# Split the dataset with 80-20 portion\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize all the data using X_train\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Use the built-in Logistic Regression function and GridSearchCV to train your model\n",
        "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "logistic_regr = LogisticRegression()\n",
        "clf = GridSearchCV(logistic_regr, parameters, cv=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Report the parameters of the best model\n",
        "print('Best parameters: ', clf.best_params_)\n",
        "\n",
        "# Report train and test accuracy of the best model\n",
        "train_preds = clf.predict(X_train)\n",
        "test_preds = clf.predict(X_test)\n",
        "print('Train accuracy: ', accuracy_score(y_train, train_preds))\n",
        "print('Test accuracy: ', accuracy_score(y_test, test_preds))\n"
      ],
      "metadata": {
        "id": "04gQoFYJmF8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}